{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "TP3-TRIED .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH2IhC7xfqyt"
      },
      "source": [
        "# **AVANT DE COMMENCER**\n",
        "\n",
        "### **Faites une copie de ce notebook dans votre drive pour être sur que vos modifications seront enregistrées.**\n",
        "\n",
        "Pour cela, aller dans *File > Save a copy in Drive*\n",
        "\n",
        "### Pour avoir accès à un GPU allez dans *Runtime > Change Runtime Type > GPU* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARc2F3-cAgGw"
      },
      "source": [
        "## Préliminaires Google Colab\n",
        "\n",
        "Pour ne pas avoir à télécharger vos donner à chaque fois que vous relancer ce notebook, vous pouvez les charger dans votre drive. **Attention, si vous choisisez cette option, une place non négligeable de votre Drive sera occupée par les jeux de donées téléchargés.** Vous pouvez choisir de ne pas le faire et vous travaillerez alors dans une session temporaire. Pour récupérer les données sur vore drive, il vous faut le monter avec la commande suivante :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zABL8wKbAT6N"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAY5ZSFTx8fA"
      },
      "source": [
        "%cd drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRA5k93rA54P"
      },
      "source": [
        "Pour la suite du TP, nous placerons nos données dans le répertoire TRIED/TP3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1BdI_1hA4ty"
      },
      "source": [
        "!mkdir TRIED\n",
        "!mkdir TRIED/TP3\n",
        "!mkdir TRIED/TP3/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhp0o2ZoExIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d12a8d-abe3-437d-e855-0cce00005a92"
      },
      "source": [
        "%cd TRIED/TP3/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TRIED/TP3/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euzqZnolB3YE",
        "outputId": "1fc93109-0fda-4e72-a620-86abdf07b519"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TRIED/TP3/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNdWU4HH-APb"
      },
      "source": [
        "# Travaux pratiques - Deep Learning avancé  \n",
        "## Exercice 0 : Fonction d’activation ReLU  \n",
        "On va comparer la fonction d’activation sigmoide utilisée dans les TP précédents par une fonction ReLU (Rectifed Linear Unit).  \n",
        "- Reprendre le perceptron à une couche cachée du TP3 en utilisant une non-linéarité ReLU. Observer le nombre d’itérations (epochs) nécessaires pour atteindre la convergence de réseau.  \n",
        "- Reprendre le réseau convolutif du TP3 en utilisant des non-linéarités ReLU pour les couches convolutives. Observer le nombre d’itérations (epochs) nécessaires pour atteindre la convergence de réseau.  \n",
        "**Conclure sur l’intérêt de la fonction d’activation ReLU.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfhFV1Zi-APi"
      },
      "source": [
        "# Transfer Learning et Fine-Tuning sur VOC2007  \n",
        "Pour aller plus loin, nous allons nous intéresser aux propriétés de « transfert » des réseaux convolutifs profonds pré-entraînés sur des bases large échelle comme ImageNet.  \n",
        "Nous allons nous intéresser à la base PASCAL VOC2007 <http://host.robots.ox.ac.uk/pascal/VOC/voc2007/>, qui est une base contenant:  \n",
        "- 20 classes (parmi les macro-catégories Person, Animal, Vehicle, Indoor), mais avec des étiquettes « multi-labels ». Par exemple, une image peut contenir à la fois une personne et un cheval.  \n",
        "- L’ensemble d’apprentissage (train+val) contient environ 5000 images, l’ensemble de test contient également environ 5000 images.  \n",
        "- Les images sont de tailles variables mais autour de 500x300. \n",
        "\n",
        "Avec des volumes de données tels que ceux de PASCAL VOC, il est impossible d’entraîner des réseaux de neurones avec autant de paramètres que ceux utilisés pour ImageNet sans être confrontés au problème du sur-apprentissage. Nous allons étudier des solutions d’apprentissage par transfert pour surmonter ce problème.\n",
        "\n",
        "Il faut au préalable avoir téléchargé les données :\n",
        "- D’apprentissage : <http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar>  \n",
        "- Et de test : <http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar>\n",
        "\n",
        "Et décompresser le tout dans un unique dossier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfgpZoPT-UKI"
      },
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "!tar -xvf VOCtrainval_06-Nov-2007.tar\n",
        "!rm VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4JW_3pn-drT"
      },
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "!tar -xvf VOCtest_06-Nov-2007.tar\n",
        "!rm VOCtest_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZDeIrmxtABG",
        "outputId": "7efde6cc-c2f8-4d8b-ccdd-611b87c92e76"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TRIED/TP3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA6HGzWq-APj"
      },
      "source": [
        "## Exercice 1 : Modèle ResNet-50 avec ``Keras``  \n",
        "Nous allons récupérer une architecture de réseau convolutif donnant des très bonnes performances sur ImageNet. On va ici s’intéresser aux réseaux ResNet [He_2016_CVPR], qui ont remporté le challenge ILSVRC en 2015. On utilisera un réseau ResNet-50 dont l’architecture détaillée peut être trouvé ici : <https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py>.  \n",
        "Avec ``Keras``, ce réseau est accessible avec le code suivant :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDm4P597-APk",
        "outputId": "f7dfc269-c41c-44c5-8dab-2d32410513b9"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50  \n",
        "model = ResNet50(include_top=True, weights='imagenet')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JxRIAAe-APl"
      },
      "source": [
        "Où les poids issus de l’entraînement sur ImageNet sont directement récupérés (``weights='imagenet'``)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-IHCoH7-APm"
      },
      "source": [
        "## Exercice 2 : Extraction de « Deep Features »  \n",
        "Une première solution pour surmonter le manque d’exemples d’apprentissage est de se servir des réseaux pré-entraînés sur ImageNet comme extracteur de descripteurs. Nous allons appliquer le réseau ResNet50 et extraire la couche d’activations du réseau avant les 1000 classes d’ImageNet, couche de taille 2048. Ainsi, l’application du réseau sur chaque image de la base produit un vecteur de taille 2048, appelé « Deep Feature ». On peut pour cela utiliser le code suivant :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nqzXwyC-APn",
        "outputId": "c1088695-24f3-479f-9e82-1686330012dd"
      },
      "source": [
        "model.layers.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7f8d6afca668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erlqKJeN-APo"
      },
      "source": [
        "L’utilisation de la fonction ``pop()`` permet de supprimer la dernière couche des (1000) classes d’ImageNet. La classe ``ResNet50`` du module ``keras.applications.resnet50`` charge un modèle de l’API fonctionnelle de Keras : <https://keras.io/getting-started/functional-api-guide/>. Pour que le dépilement de la dernière couche ait un effet sur le modèle, il faut le préciser explicitement :  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEuCYPUj-APo"
      },
      "source": [
        "from keras.models import Model\n",
        "model = Model(inputs=model.input, outputs=model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2af-B0Lm-APo"
      },
      "source": [
        "### TODO \n",
        "* Vérifier l’architecture du modèle \n",
        "* Le compiler (pour l’extraction futures des Deep Features). On prendra une descente de gradient stochastique comme méthode d'optimisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX1Q6JFv-APp"
      },
      "source": [
        "##################### VOTRE CODE ICI ############\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfOiQQIr-APq"
      },
      "source": [
        "**Chargement des données de la base.** Stocker en mémoire l’ensemble des données devient impossible pour des bases de données massives. On arrive à la limite sur VOC 2007 ou le tenseur d’entrée prend plusieurs Go de mémoire. Au lieu de charger l’intégralité des données on va s’appuyer sur une fonction génératrice, i.e. capable de générer à la volée un batch d’exemples sur lequel calculer une étape forward pour l’extraction des « Deep Features ».  \n",
        "Sur la base VOC 2007, on utilisera le générateur ``PascalVOCDataGenerator`` fourni : <http://cedric.cnam.fr/~thomen/cours/US330X/data_gen.py>. On instanciera le générateur sur la base d’apprentissage de la manière suivante :  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbkG1YrVEhx-",
        "outputId": "3f93941b-56c0-4e6a-a804-40c99fafdefd"
      },
      "source": [
        "!wget http://cedric.cnam.fr/~thomen/cours/US330X/data_gen.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-14 15:22:46--  http://cedric.cnam.fr/~thomen/cours/US330X/data_gen.py\n",
            "Resolving cedric.cnam.fr (cedric.cnam.fr)... 163.173.128.10\n",
            "Connecting to cedric.cnam.fr (cedric.cnam.fr)|163.173.128.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5351 (5.2K) [text/x-python]\n",
            "Saving to: ‘data_gen.py’\n",
            "\n",
            "data_gen.py         100%[===================>]   5.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-14 15:22:46 (471 MB/s) - ‘data_gen.py’ saved [5351/5351]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXpGZoeS-APr"
      },
      "source": [
        "from data_gen import PascalVOCDataGenerator  \n",
        "data_dir = 'data/VOCdevkit/VOC2007/' # A changer avec votre chemin  \n",
        "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX9mkOzt-APr"
      },
      "source": [
        "Le générateur contient un dictionnaire dont les clés correspondent aux identifiants des images de la base (e.g. 000012), et les clés sont le vecteur codé au format « one-hot » (par exemple [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] va indiquer que l’image contient les classes bicycle et person). Un générateur va être crée par l’appel de la méthode ``flow`` :  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvG2HBOM-APs"
      },
      "source": [
        "batch_size = 32\n",
        "generator = data_generator_train.flow(batch_size=batch_size) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc2zO5Ck-APs"
      },
      "source": [
        "L’appel de ``next()`` sur le générateur va permettre d’exécuter le code à l’intérieur de la bouche ``while`` de ``flow``, i.e. :  \n",
        "- Charger en mémoire le batch d’images et de labels suivant  \n",
        "- Retailler chaque image en une taille précisée (224x224)  \n",
        "- Appliquer un pré-traitement à l’image (soustraction de l’image moyenne d’ImageNet)\n",
        "\n",
        "Ainsi, on va pouvoir utiliser ce générateur afin d’extraire séquentiellement les données des PASCAL VOC 2007, et d’extraire les « Deep Features » :\n",
        "\n",
        "### TODO\n",
        "\n",
        "* Utiliser ce générateur afin d'extraire séquentiellement les données de PASCAL VOC 2007\n",
        "* Extraire les Deep Features de la base en train\n",
        "* Répéter l'extraction sur les images de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akm9MT8n-APs"
      },
      "source": [
        "import numpy as np\n",
        "batch_size = 32  \n",
        "generator = data_generator_train.flow(batch_size=batch_size)\n",
        "Nb_images = len(data_generator_train.images_ids_in_subset) # Nombre d'images\n",
        "# Initilisation des matrices contenant les Deep Features et les labels \n",
        "X_train = # TODO...\n",
        "Y_train = # TODO...\n",
        "# Calcul du nombre de batchs  \n",
        "nb_batches = int(len(data_generator_train.images_ids_in_subset) / batch_size) + 1  \n",
        "\n",
        "for i in range(nb_batches):  \n",
        "    # Pour chaque batch, on extrait les images d'entrée X et les labels y  \n",
        "    X, y = next(generator)\n",
        "    # On récupère les Deep Feature\n",
        "    # TODO..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot0VZH4d2iqu"
      },
      "source": [
        "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
        "batch_size = 32  \n",
        "generator = data_generator_test.flow(batch_size=batch_size)\n",
        "Nb_images = len(data_generator_test.images_ids_in_subset) # Nombre d'images\n",
        "# Extraction des images et des deep features\n",
        "# TODO..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ-_cIzA-APs"
      },
      "source": [
        "Le temps d’extraction en CPU pour être long (plus d’une minute par batch de 32 images). L’utilisation du GPU accélère considérablement le calcul. On calculera de manière identique la matrice des Deep Features sur la base de test. Finalement, on sauvegardera les Deep Features et labels de la manière suivante :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBT1Toym-APs"
      },
      "source": [
        "outfile = 'DF_ResNet50_VOC2007'  \n",
        "np.savez(outfile, X_train=X_train, Y_train=Y_train,X_test=X_test, Y_test=Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yEKVbxJ-APs"
      },
      "source": [
        "## Exercice 3 : Transfert sur VOC 2007  \n",
        "On commencera par charger les données calculées à l’exercice précédent (téléchargeables directement ici : <http://cedric.cnam.fr/~thomen/cours/US330X/DF_ResNet50_VOC2007.npz>) :  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_8RsH92-APt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da263035-fd20-496d-edf6-c862d7f71a90"
      },
      "source": [
        "outfile = 'DF_ResNet50_VOC2007.npz'  \n",
        "npzfile = np.load(outfile)  \n",
        "X_train = npzfile['X_train']  \n",
        "Y_train = npzfile['Y_train']  \n",
        "X_test = npzfile['X_test']  \n",
        "Y_test = npzfile['Y_test']  \n",
        "print(\"X_train=\",X_train.shape, \"Y_train=\",Y_train.shape, \" X_test=\",X_test.shape, \"Y_train=\",Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train= (4952, 2048) Y_train= (4952, 20)  X_test= (4952, 2048) Y_train= (4952, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYyuwDdh-APt"
      },
      "source": [
        "On va maintenant considérer les Deep Features comme les données d’entrée et définir un réseau de neurones complètement connectés sans couche cachée pour prédire les labels de sortie.\n",
        "\n",
        "### TODO\n",
        "\n",
        "* Créer un modèle d'une seule couche permettant la classification des features\n",
        "* On prendra une fonction d'activation de type sigmoïde\n",
        "* Le compiler\n",
        "* L'entrainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRUJPm7h-APt"
      },
      "source": [
        "########## VOTRE CODE ICI #####################\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkibvYlD-APt"
      },
      "source": [
        "### Question :  \n",
        "Justifier le choix de la fonction d’activation de type sigmoïde par rapport à la fonction softmax habituelle.  \n",
        "On va maintenant compiler le modèle de la manière suivante :  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YQ3breg-APv"
      },
      "source": [
        "### Question :  \n",
        "Observer le code source de la fonction binary_crossentropy : <https://github.com/keras-team/keras/blob/master/keras/losses.py/>. Expliquer le calcul effectué dans notre cas et justifier pourquoi cette fonction de coût est adaptée au contexte multi-label.  \n",
        "On va pouvoir entraîner et évaluer le modèle classiquement :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI5rCiMX-APv"
      },
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose=0)  \n",
        "print(\"%s TEST: %.2f%%\" % (model.metrics_names[0], scores[0]*100))  \n",
        "print(\"%s TEST: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8POQi-H-APv"
      },
      "source": [
        "**Évaluation finale de performances.** La métrique utilisée pour évaluer les performances sur PASCAL VOC est la Précision Moyenne (Average Precision). \n",
        "\n",
        "### TODO\n",
        "\n",
        "* Calculer la précision pour chaque classe en utilisant la fonction average_precision_score de la bibliothèque Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDvrxqPl-APv"
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "y_pred_test = model.predict(X_test)  \n",
        "y_pred_train = model.predict(X_train)  \n",
        "AP_train = np.zeros(20)  \n",
        "AP_test = np.zeros(20)  \n",
        "for c in range(20):  \n",
        "    #TODO...\n",
        "  \n",
        "print(\"MAP TRAIN =\", AP_train.mean()*100)  \n",
        "print(\"MAP TEST =\", AP_test.mean()*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUfz12Kv-APv"
      },
      "source": [
        "### Question :  \n",
        "Quel MAP obtenez-vous sur la base de test ?  \n",
        "## Exercice 4 : Fine-tuning sur VOC 2007  \n",
        "Enfin, on va tester un apprentissage où les paramètres du réseau seront initialisées sur la base ImageNet, mais fine-tunées sur VOC2007 pour spécialiser les représentations internes à la base cible et améliorer les performances. **N.B. : il faut impérativement utiliser une carte GPU dans cette partie.**  \n",
        "On commencera pour cela à charger le réseau et ajouter la couche de classification dédiée à VOC2007 :  \n",
        "\n",
        "### TODO\n",
        "\n",
        "* Retirer la dernière couche du modèle et la remplacer par une couche complètement connectée de taille adaptée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTVKQDOY-APv"
      },
      "source": [
        "# Load ResNet50 architecture & its weights  \n",
        "model = ResNet50(include_top=True, weights='imagenet')  \n",
        "model.layers.pop()  \n",
        "# Modify top layers\n",
        "# TODO..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk7xVDYq-APw"
      },
      "source": [
        "On spécifiera ensuite qu’on souhaite apprendre les paramètres de l’ensemble du réseau :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5U3tUCE-APw"
      },
      "source": [
        "for i in range(len(model.layers)):\n",
        "  model.layers[i].trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3JA8HVl-APx"
      },
      "source": [
        "### Question :  \n",
        "Si on avait indiqué ``model.layers[i].trainable = False`` pour toutes les couches sauf la dernière, dans quel mode serions-nous ?  \n",
        "On va ensuite compiler le modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wso_XiEG-APx"
      },
      "source": [
        "lr = 0.1  \n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr), metrics=['binary_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGjBsEqU-APx"
      },
      "source": [
        "Et simplement utiliser la méthode ``fit_generator`` pour entraîner le modèle\n",
        "\n",
        "* ``fit_generator`` va prendre en paramètre la fonction ``flow`` qui va renvoyer un batch d’exemples et de labels. La méthode forward va comparer la sortie prédite par le modèle aux labels données par la supervision puis l’étape backward va mettre à jour l’ensemble des paramètres du modèle.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBrs_9QO-APy"
      },
      "source": [
        "batch_size=32  \n",
        "nb_epochs=10  \n",
        "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)  \n",
        "steps_per_epoch_train = int(len(data_generator_train.id_to_label) / batch_size) + 1  \n",
        "model.fit_generator(data_generator_train.flow(batch_size=batch_size),  \n",
        "                    steps_per_epoch=steps_per_epoch_train,  \n",
        "                    epochs=nb_epochs,  \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibyyhDj_-APy"
      },
      "source": [
        "### TODO\n",
        "\n",
        "* Évaluer le modèle sur la base de test\n",
        "* Calculer le MAP\n",
        "\n",
        "### Question :  \n",
        "Quel MAP obtenez-vous sur la base de test dans ce régime de fine-tuning ? Conclure.  "
      ]
    }
  ]
}